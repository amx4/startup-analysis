{
 "nbformat_minor": 0, 
 "nbformat": 4, 
 "cells": [
  {
   "execution_count": 2, 
   "cell_type": "code", 
   "source": [
    "from bs4 import BeautifulSoup\n", 
    "import urllib2\n", 
    "import urllib\n", 
    "import json\n", 
    "import csv\n", 
    "import time\n", 
    "import pickle\n", 
    "import pandas as pd"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": true
   }
  }, 
  {
   "execution_count": 151, 
   "cell_type": "code", 
   "source": [
    "html_pages = load_obj(\"angel_html_c_full\")"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "execution_count": null, 
   "cell_type": "code", 
   "source": [
    "def backup(obj, iter_num):\n", 
    "    name = \"fin_data_\" + str(iter_num)\n", 
    "    with open(name + '.pkl', 'wb') as f:\n", 
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n", 
    "        \n", 
    "def load_obj(name):\n", 
    "    with open(name + '.pkl', 'rb') as f:\n", 
    "        return pickle.load(f)"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": true
   }
  }, 
  {
   "execution_count": null, 
   "cell_type": "code", 
   "source": [
    "request_headers = {\"Host\": \"angel.co\",\n", 
    "\"Connection\": \"keep-alive\",\n", 
    "\"Content-Length\": \"18\",\n", 
    "\"Origin\": \"https://angel.co\",\n", 
    "\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36\",\n", 
    "\"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n", 
    "\"Accept\": \"*/*\",\n", 
    "\"X-Requested-With\": \"XMLHttpRequest\",\n", 
    "\"Referer\": \"https://angel.co/companies\",\n", 
    "\"Accept-Language\": \"en-US,en;q=0.8\",\n", 
    "}\n", 
    "\n", 
    "\n", 
    "start = time.time()\n", 
    "#html_pages = {}\n", 
    "for page in range(3500):\n", 
    "    link = \"https://angel.co/company_filters/search_data\"\n", 
    "    data = urllib.urlencode({\"page\":str(page), \"sort\":\"raised\"})\n", 
    "    request = urllib2.Request(link, headers=request_headers)\n", 
    "    contents = urllib2.urlopen(request, data=data).read()\n", 
    "    content_d = json.loads(contents)\n", 
    "    beg = \"https://angel.co/companies/startups?\" + \"&\".join([\"ids%5B%5D=\" + str(id) for id in content_d['ids']])\n", 
    "    end = \"&total=\" + str(content_d[\"total\"]) + \"&page=\" + str(content_d[\"page\"]) + \"&sort=\" + str(content_d[\"sort\"]) + \"&new=\" + str(content_d[\"new\"]) + \"&hexdigest=\" + str(content_d[\"hexdigest\"])\n", 
    "    link = beg + end\n", 
    "    html_pages[page] = urllib2.urlopen(link).read()\n", 
    "    \n", 
    "    time.sleep(1)\n", 
    "    if page % 100 == 0:\n", 
    "        mins = (time.time() - start) / 60\n", 
    "        print 'Percent progress ' + str(100 * float(page) / 3500) + ' running for ' + str(mins) + ' mins'\n", 
    "        backup(html_pages, page)"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": true
   }
  }, 
  {
   "execution_count": null, 
   "cell_type": "code", 
   "source": [
    "request_headers = {\"Host\": \"angel.co\",\n", 
    "\"Connection\": \"keep-alive\",\n", 
    "#\"Content-Length\": \"100\",\n", 
    "\"Origin\": \"https://angel.co\",\n", 
    "\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36\",\n", 
    "\"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n", 
    "\"Accept\": \"*/*\",\n", 
    "\"X-Requested-With\": \"XMLHttpRequest\",\n", 
    "\"Referer\": \"https://angel.co/companies\",\n", 
    "\"Accept-Language\": \"en-US,en;q=0.8\",\n", 
    "\"DNT\": \"1\"}\n", 
    "\n", 
    "start = time.time()\n", 
    "html_pages_c = []\n", 
    "vals = range(0, 100000000, 100000)\n", 
    "max_val = vals[1:]\n", 
    "min_val = vals[0:-1]\n", 
    "base_url = \"https://angel.co/company_filters/search_data\" \n", 
    "print 'Starting'\n", 
    "for i in range(999):\n", 
    "    min_v, max_v = min_val[i], max_val[i]\n", 
    "    for page in range(20):\n", 
    "        data=\"filter_data%5Braised%5D%5Bmin%5D=\" + str(min_v) + \"&filter_data%5Braised%5D%5Bmax%5D=\" + str(max_v) + \"&sort=signal&page=\" + str(page)\n", 
    "        request = urllib2.Request(base_url, headers=request_headers)\n", 
    "        contents = urllib2.urlopen(request, data=data).read()\n", 
    "        content_d = json.loads(contents)\n", 
    "        if content_d['ids'] != []:\n", 
    "            beg = \"https://angel.co/companies/startups?\" + \"&\".join([\"ids%5B%5D=\" + str(id) for id in content_d['ids']])\n", 
    "            end = \"&total=\" + str(content_d[\"total\"]) + \"&page=\" + str(content_d[\"page\"]) + \"&sort=\" + str(content_d[\"sort\"]) + \"&new=\" + str(content_d[\"new\"]) + \"&hexdigest=\" + str(content_d[\"hexdigest\"])\n", 
    "            link = beg + end\n", 
    "            html_pages_c.append(urllib2.urlopen(link).read())\n", 
    "        else:\n", 
    "            break\n", 
    "        time.sleep(0.1)\n", 
    "    if i % 50 == 0:\n", 
    "        mins = (time.time() - start) / 60\n", 
    "        print 'Percent progress ' + str(100 * i / 50.0) + ' running for ' + str(mins) + ' mins'\n", 
    "        backup(html_pages_c, max_v)\n", 
    "backup(html_pages_c, \"full\")"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": true
   }
  }, 
  {
   "execution_count": 152, 
   "cell_type": "code", 
   "source": [
    "# All possible fields\n", 
    "\n", 
    "soup = BeautifulSoup(html_pages[1], \"lxml\")\n", 
    "soup.find_all(\"div\", class_=\"pitch\")[0]\n", 
    "soup.find_all(\"div\", class_=\"value\")[0]\n", 
    "soup.find_all(\"div\", class_=\"market\")[0]\n", 
    "soup.find_all(\"div\", class_=\"website\")[0]\n", 
    "soup.find_all(\"div\", class_=\"joined\")[0]\n", 
    "soup.find_all(\"div\", class_=\"location\")[0]\n", 
    "soup.find_all(\"div\", class_=\"company_size\")[0]\n", 
    "soup.find_all(\"div\", class_=\"stage\")[0]\n", 
    "soup.find_all(\"div\", class_=\"raised\")[0]"
   ], 
   "outputs": [
    {
     "execution_count": 152, 
     "output_type": "execute_result", 
     "data": {
      "text/plain": [
       "<div class=\"column hidden_column raised sortable\" data-column=\"raised\">\\\\nTotal Raised\\\\n</div>"
      ]
     }, 
     "metadata": {}
    }
   ], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "execution_count": 155, 
   "cell_type": "code", 
   "source": [
    "len_pages = len(html_pages)\n", 
    "print 'Starting'\n", 
    "start = time.time()\n", 
    "names, raised, pitch, stage, market = [], [], [], [], []\n", 
    "for i in range(1, len_pages): \n", 
    "    soup = BeautifulSoup(html_pages[i], \"lxml\")\n", 
    "    names_unf = soup.find_all(\"div\", class_=\"name\")\n", 
    "    raised_unf = soup.find_all(\"div\", class_=\"raised\")\n", 
    "    pitch_unf = soup.find_all(\"div\", class_=\"pitch\")\n", 
    "    stage_unf = soup.find_all(\"div\", class_=\"stage\")\n", 
    "    market_unf = soup.find_all(\"div\", class_=\"market\")\n", 
    "    if i % 100 == 0:\n", 
    "        mins = (time.time() - start) / 60\n", 
    "        print 'Percent progress ' + str(100 * float(i) / len_pages) + ' running for ' + str(mins) + ' mins'\n", 
    "    \n", 
    "    res_len = min(len(names_unf), len(raised_unf), len(pitch_unf), \n", 
    "        len(stage_unf), len(market_unf))\n", 
    "    for j in range(res_len): \n", 
    "        names.append(names_unf[j].text[2:-2])\n", 
    "        raised.append(raised_unf[j].text[22:-4])\n", 
    "        pitch.append(pitch_unf[j].text[2:-2])\n", 
    "        stage.append(stage_unf[j].text[15:-4])\n", 
    "        market.append(market_unf[j].text[16:-4])\n", 
    "\n", 
    "startup_data_full = {\"Names\":names, \"Raised\": raised, \"Pitch\":pitch, \"Stage\":stage, \"Market\":market} "
   ], 
   "outputs": [
    {
     "output_type": "stream", 
     "name": "stdout", 
     "text": [
      "Starting\n", 
      "Percent progress 3.34784064279 running for 0.221906415621 mins\n", 
      "Percent progress 6.69568128557 running for 0.435572417577 mins\n", 
      "Percent progress 10.0435219284 running for 0.655195017656 mins\n", 
      "Percent progress 13.3913625711 running for 0.875916063786 mins\n", 
      "Percent progress 16.7392032139 running for 1.09028981527 mins\n", 
      "Percent progress 20.0870438567 running for 1.30546389818 mins\n", 
      "Percent progress 23.4348844995 running for 1.5151494503 mins\n", 
      "Percent progress 26.7827251423 running for 1.7292738835 mins\n", 
      "Percent progress 30.1305657851 running for 1.9336484313 mins\n", 
      "Percent progress 33.4784064279 running for 2.13388544718 mins\n", 
      "Percent progress 36.8262470706 running for 2.34065020084 mins\n", 
      "Percent progress 40.1740877134 running for 2.5415830493 mins\n", 
      "Percent progress 43.5219283562 running for 2.73126256466 mins\n", 
      "Percent progress 46.869768999 running for 2.91019073327 mins\n", 
      "Percent progress 50.2176096418 running for 3.08468063275 mins\n", 
      "Percent progress 53.5654502846 running for 3.25285019875 mins\n", 
      "Percent progress 56.9132909274 running for 3.39065463146 mins\n", 
      "Percent progress 60.2611315701 running for 3.52289288044 mins\n", 
      "Percent progress 63.6089722129 running for 3.636827751 mins\n", 
      "Percent progress 66.9568128557 running for 3.74423604806 mins\n", 
      "Percent progress 70.3046534985 running for 3.82825569709 mins\n", 
      "Percent progress 73.6524941413 running for 3.89962738355 mins\n", 
      "Percent progress 77.0003347841 running for 3.97745383183 mins\n", 
      "Percent progress 80.3481754268 running for 4.03767399788 mins\n", 
      "Percent progress 83.6960160696 running for 4.09286113183 mins\n", 
      "Percent progress 87.0438567124 running for 4.14844601552 mins\n", 
      "Percent progress 90.3916973552 running for 4.18850261768 mins\n", 
      "Percent progress 93.739537998 running for 4.22833424807 mins\n", 
      "Percent progress 97.0873786408 running for 4.27367318074 mins\n"
     ]
    }
   ], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "execution_count": 212, 
   "cell_type": "code", 
   "source": [
    "names = [name.replace(' ', '-') for name in names]\n", 
    "startup_data_full = {\"Names\":names, \"Raised\": raised, \"Pitch\":pitch, \"Stage\":stage, \"Market\":market} \n", 
    "startup_df = pd.DataFrame(startup_data_full)\n", 
    "startup_df.head()"
   ], 
   "outputs": [
    {
     "execution_count": 212, 
     "output_type": "execute_result", 
     "data": {
      "text/plain": [
       "               Market                    Names  \\\n", 
       "0                                    Unwind-Me   \n", 
       "1        Marketplaces  Jackson-Square-Ventures   \n", 
       "2                SaaS         Contour-Ventures   \n", 
       "3                   -              GSV-Capital   \n", 
       "4  Financial Services            Vast-Ventures   \n", 
       "\n", 
       "                                               Pitch Raised Stage  \n", 
       "0  Massage Made Simple: The best therapists, stra...               \n", 
       "1       VC firm investing in SaaS and marketplaces.       -        \n", 
       "2                                                         -     -  \n", 
       "3                                                         -     -  \n", 
       "4              Investing to improve human potential       -     -  "
      ], 
      "text/html": [
       "<div>\n", 
       "<table border=\"1\" class=\"dataframe\">\n", 
       "  <thead>\n", 
       "    <tr style=\"text-align: right;\">\n", 
       "      <th></th>\n", 
       "      <th>Market</th>\n", 
       "      <th>Names</th>\n", 
       "      <th>Pitch</th>\n", 
       "      <th>Raised</th>\n", 
       "      <th>Stage</th>\n", 
       "    </tr>\n", 
       "  </thead>\n", 
       "  <tbody>\n", 
       "    <tr>\n", 
       "      <th>0</th>\n", 
       "      <td></td>\n", 
       "      <td>Unwind-Me</td>\n", 
       "      <td>Massage Made Simple: The best therapists, stra...</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>1</th>\n", 
       "      <td>Marketplaces</td>\n", 
       "      <td>Jackson-Square-Ventures</td>\n", 
       "      <td>VC firm investing in SaaS and marketplaces.</td>\n", 
       "      <td>-</td>\n", 
       "      <td></td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>2</th>\n", 
       "      <td>SaaS</td>\n", 
       "      <td>Contour-Ventures</td>\n", 
       "      <td></td>\n", 
       "      <td>-</td>\n", 
       "      <td>-</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>3</th>\n", 
       "      <td>-</td>\n", 
       "      <td>GSV-Capital</td>\n", 
       "      <td></td>\n", 
       "      <td>-</td>\n", 
       "      <td>-</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>4</th>\n", 
       "      <td>Financial Services</td>\n", 
       "      <td>Vast-Ventures</td>\n", 
       "      <td>Investing to improve human potential</td>\n", 
       "      <td>-</td>\n", 
       "      <td>-</td>\n", 
       "    </tr>\n", 
       "  </tbody>\n", 
       "</table>\n", 
       "</div>"
      ]
     }, 
     "metadata": {}
    }
   ], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "execution_count": 195, 
   "cell_type": "code", 
   "source": [
    "comp_data = {}\n", 
    "companies = list(startup_df['Names'].unique())\n", 
    "companies = [company.replace(' ', '-') for company in companies]\n", 
    "error_comps = []\n", 
    "companies_len = len(companies)\n", 
    "for i in range(companies_len):\n", 
    "    try:\n", 
    "        company = companies[i]\n", 
    "        link = \"https://angel.co/\" + company + \"?utm_source=companies\"\n", 
    "        soup = BeautifulSoup(urllib2.urlopen(link).read(), \"lxml\")\n", 
    "        fin_details = soup.find_all(\"div\", class_=\"details\")\n", 
    "        comp_data[company] = {\"finance\":[]}\n", 
    "        for fin_detail in fin_details:\n", 
    "            fin_round = fin_detail.find_all(\"div\", class_=\"type\")[0].text[1:-1]\n", 
    "            fin_date = fin_detail.find_all(\"div\", class_ =\"date_display\")[0].text\n", 
    "            fin_amount = fin_detail.find_all(\"div\", class_=\"raised\")\n", 
    "            fin_amount = fin_amount[0].text[1:-1]\n", 
    "            comp_data[company][\"finance\"].append((fin_round, fin_date, fin_amount))\n", 
    "        prod_desc = soup.find_all(\"div\", class_=\"product_desc\")[0]\n", 
    "        comp_data[company][\"desc\"] = prod_desc.find_all(\"div\", class_=\"content\")[0].text[1: -1]\n", 
    "        if i % 1000 == 0:\n", 
    "            mins = (time.time() - start) / 60\n", 
    "            print 'Percent progress ' + str(100.0 * i / companies_len) + ' running for ' + str(mins) + ' mins'\n", 
    "            backup(comp_data, companies.index(company))\n", 
    "    except:\n", 
    "        error_comps.append(company)"
   ], 
   "outputs": [
    {
     "output_type": "stream", 
     "name": "stdout", 
     "text": [
      "Percent progress 0.0 running for 20.6441246311 mins\n", 
      "Percent progress 69.3200854948 running for 310.646753867 mins\n", 
      "Percent progress 92.4267806597 running for 405.472500134 mins\n"
     ]
    }
   ], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "execution_count": 242, 
   "cell_type": "code", 
   "source": [
    "fin_data = load_obj('fin_data_full')\n", 
    "\n", 
    "def fin_isvalid(data):\n", 
    "    stages = [dets[0] for dets in data]\n", 
    "    if any(\"Series B\" in s for s in stages) or any(\"Series C\" in s for s in stages):\n", 
    "        if stages.count('Series A') < 2 and stages.count('Series B') < 2 and stages.count('Series C') < 2 and stages.count('Series D') < 2:\n", 
    "                return True\n", 
    "    return False\n", 
    "name, fin, desc = [], [], []\n", 
    "for k in fin_data.keys():\n", 
    "    if fin_data[k].has_key('finance'):\n", 
    "        if fin_isvalid(fin_data[k]['finance']):\n", 
    "            name.append(k)\n", 
    "            fin.append(fin_data[k]['finance'])\n", 
    "            if fin_data[k].has_key('desc'):\n", 
    "                desc.append(fin_data[k]['desc'])\n", 
    "            else:\n", 
    "                desc.append('')   \n", 
    "\n", 
    "no_stage, seed, series_a, series_b, series_c, series_d = [], [], [], [], [], []\n", 
    "for fin_list in fin:\n", 
    "    c_no_stage, c_seed, c_series_a, c_series_b, c_series_c, c_series_d = [], [], [], [], [], []\n", 
    "    for fin_round in fin_list:\n", 
    "        if fin_round[0] == 'Seed':\n", 
    "            c_seed.append(fin_round)\n", 
    "        elif fin_round[0] == 'No Stage':\n", 
    "            c_no_stage.append(fin_round)\n", 
    "        elif fin_round[0] == 'Series A':\n", 
    "            c_series_a.append(fin_round)\n", 
    "        elif fin_round[0] == 'Series B':\n", 
    "            c_series_b.append(fin_round)\n", 
    "        elif fin_round[0] == 'Series C':\n", 
    "            c_series_c.append(fin_round)\n", 
    "        elif fin_round[0] == 'Series D':\n", 
    "            c_series_d.append(fin_round)\n", 
    "    no_stage.append(c_no_stage)\n", 
    "    seed.append(c_seed)\n", 
    "    series_a.append(c_series_a)\n", 
    "    series_b.append(c_series_b)\n", 
    "    series_c.append(c_series_c)\n", 
    "    series_d.append(c_series_d)\n", 
    "for funding in [seed, no_stage, series_a, series_b, series_c, series_d]:\n", 
    "    for i in range(len(funding)):\n", 
    "        ele = funding[i]\n", 
    "        if ele == []:\n", 
    "            funding[i] = ('', '', '')\n", 
    "        else:\n", 
    "            funding[i] = ele[0]\n", 
    "            \n", 
    "seed_amount = [val[2] for val in seed]\n", 
    "no_stage_amount = [val[2] for val in no_stage]\n", 
    "series_a_amount = [val[2] for val in series_a]\n", 
    "series_b_amount = [val[2] for val in series_b]\n", 
    "series_c_amount = [val[2] for val in series_c]\n", 
    "series_d_amount = [val[2] for val in series_d]\n", 
    "\n", 
    "seed_date = [val[1] for val in seed]\n", 
    "no_stage_date = [val[1] for val in no_stage]\n", 
    "series_a_date = [val[1] for val in series_a]\n", 
    "series_b_date = [val[1] for val in series_b]\n", 
    "series_c_date = [val[1] for val in series_c]\n", 
    "series_d_date = [val[1] for val in series_d]\n", 
    "\n", 
    "market, pitch, stage = [], [], []\n", 
    "for comp in name:\n", 
    "    companydf = startup_df[startup_df[\"Names\"] == comp]\n", 
    "    market.append(list(companydf.Market)[0])\n", 
    "    pitch.append(list(companydf.Pitch)[0])\n", 
    "    stage.append(list(companydf.Stage)[0])\n", 
    "\n", 
    "funding_full = {\"Names\":name, \"Market\": market, \"Pitch\": pitch, \"Stage\": stage, \"Description\":desc,\n", 
    "                \"No_Stage_Date\": no_stage_date, \"No_Stage_Amount\":no_stage_amount,                \n", 
    "                \"Seed_Date\": seed_date, \"Seed_Amount\":seed_amount,\n", 
    "                \"Series_A_Date\": series_a_date, \"Series_A_Amount\":series_a_amount, \n", 
    "                \"Series_B_Date\":series_b_date, \"Series_B_Amount\":series_b_amount, \n", 
    "                \"Series_C_Date\":series_c_date, \"Series_C_Amount\":series_c_amount,\n", 
    "                \"Series_D_Date\":series_d_date, \"Series_D_Amount\":series_d_amount} \n", 
    "funding_df = pd.DataFrame(funding_full)\n", 
    "funding_df = funding_df[funding_df[\"Stage\"] != \"Acquired\"]\n", 
    "funding_df.head()"
   ], 
   "outputs": [
    {
     "execution_count": 242, 
     "output_type": "execute_result", 
     "data": {
      "text/plain": [
       "                                         Description  \\\n", 
       "1                                                      \n", 
       "2                                                      \n", 
       "3  Visualead (\u89c6\u89c9\u7801) creates better interactions be...   \n", 
       "4                                                      \n", 
       "5                                                      \n", 
       "\n", 
       "                        Market             Names No_Stage_Amount  \\\n", 
       "1                        Cable     Epic-Sciences                   \n", 
       "2                 All Students  Apreso-Classroom                   \n", 
       "3  Bridging Online and Offline         Visualead                   \n", 
       "4              Food Processing           Onshift      $7,000,000   \n", 
       "5                            -    Xendex-Holding                   \n", 
       "\n", 
       "  No_Stage_Date                                              Pitch  \\\n", 
       "1                                                                    \n", 
       "2                                                                    \n", 
       "3                Effective and Secure Offline to Mobile experie...   \n", 
       "4  Feb  3, 2014                                                      \n", 
       "5                                                                    \n", 
       "\n", 
       "  Seed_Amount     Seed_Date Series_A_Amount Series_A_Date Series_B_Amount  \\\n", 
       "1                                                             $13,000,000   \n", 
       "2                                                             $15,000,000   \n", 
       "3    $750,000  Mar 25, 2012      $1,600,000  Aug 15, 2013         Unknown   \n", 
       "4                                                              $3,000,000   \n", 
       "5                                   Unknown  Jun 25, 2008      $3,500,000   \n", 
       "\n", 
       "  Series_B_Date Series_C_Amount Series_C_Date Series_D_Amount Series_D_Date  \\\n", 
       "1  Nov 13, 2012     $30,000,000  Jul 30, 2014                                 \n", 
       "2  Oct 14, 2008                                                               \n", 
       "3  Jan 20, 2015                                                               \n", 
       "4  Feb  2, 2012                                                               \n", 
       "5  Nov 30, 2009                                                               \n", 
       "\n", 
       "      Stage  \n", 
       "1  Series C  \n", 
       "2  Series B  \n", 
       "3  Series B  \n", 
       "4  Series C  \n", 
       "5  Series A  "
      ], 
      "text/html": [
       "<div>\n", 
       "<table border=\"1\" class=\"dataframe\">\n", 
       "  <thead>\n", 
       "    <tr style=\"text-align: right;\">\n", 
       "      <th></th>\n", 
       "      <th>Description</th>\n", 
       "      <th>Market</th>\n", 
       "      <th>Names</th>\n", 
       "      <th>No_Stage_Amount</th>\n", 
       "      <th>No_Stage_Date</th>\n", 
       "      <th>Pitch</th>\n", 
       "      <th>Seed_Amount</th>\n", 
       "      <th>Seed_Date</th>\n", 
       "      <th>Series_A_Amount</th>\n", 
       "      <th>Series_A_Date</th>\n", 
       "      <th>Series_B_Amount</th>\n", 
       "      <th>Series_B_Date</th>\n", 
       "      <th>Series_C_Amount</th>\n", 
       "      <th>Series_C_Date</th>\n", 
       "      <th>Series_D_Amount</th>\n", 
       "      <th>Series_D_Date</th>\n", 
       "      <th>Stage</th>\n", 
       "    </tr>\n", 
       "  </thead>\n", 
       "  <tbody>\n", 
       "    <tr>\n", 
       "      <th>1</th>\n", 
       "      <td></td>\n", 
       "      <td>Cable</td>\n", 
       "      <td>Epic-Sciences</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$13,000,000</td>\n", 
       "      <td>Nov 13, 2012</td>\n", 
       "      <td>$30,000,000</td>\n", 
       "      <td>Jul 30, 2014</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series C</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>2</th>\n", 
       "      <td></td>\n", 
       "      <td>All Students</td>\n", 
       "      <td>Apreso-Classroom</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$15,000,000</td>\n", 
       "      <td>Oct 14, 2008</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series B</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>3</th>\n", 
       "      <td>Visualead (\u89c6\u89c9\u7801) creates better interactions be...</td>\n", 
       "      <td>Bridging Online and Offline</td>\n", 
       "      <td>Visualead</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Effective and Secure Offline to Mobile experie...</td>\n", 
       "      <td>$750,000</td>\n", 
       "      <td>Mar 25, 2012</td>\n", 
       "      <td>$1,600,000</td>\n", 
       "      <td>Aug 15, 2013</td>\n", 
       "      <td>Unknown</td>\n", 
       "      <td>Jan 20, 2015</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series B</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>4</th>\n", 
       "      <td></td>\n", 
       "      <td>Food Processing</td>\n", 
       "      <td>Onshift</td>\n", 
       "      <td>$7,000,000</td>\n", 
       "      <td>Feb  3, 2014</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$3,000,000</td>\n", 
       "      <td>Feb  2, 2012</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series C</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>5</th>\n", 
       "      <td></td>\n", 
       "      <td>-</td>\n", 
       "      <td>Xendex-Holding</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Unknown</td>\n", 
       "      <td>Jun 25, 2008</td>\n", 
       "      <td>$3,500,000</td>\n", 
       "      <td>Nov 30, 2009</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series A</td>\n", 
       "    </tr>\n", 
       "  </tbody>\n", 
       "</table>\n", 
       "</div>"
      ]
     }, 
     "metadata": {}
    }
   ], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "execution_count": 3, 
   "cell_type": "code", 
   "source": [
    "funding_df=pd.read_csv(\"funding.csv\")\n", 
    "funding_df.fillna('', inplace=True)\n", 
    "funding_df.head(10)"
   ], 
   "outputs": [
    {
     "execution_count": 3, 
     "output_type": "execute_result", 
     "data": {
      "text/plain": [
       "                                         Description  \\\n", 
       "0                                                      \n", 
       "1                                                      \n", 
       "2  Visualead (\u89c6\u89c9\u7801) creates better interactions be...   \n", 
       "3                                                      \n", 
       "4                                                      \n", 
       "5  Palo Alto-based FilmLoop has reportedly layed ...   \n", 
       "6                                                      \n", 
       "7                                                      \n", 
       "8  Challenge your brain with games designed by ne...   \n", 
       "9  ROBLOX is a comprehensive 3D creation, publish...   \n", 
       "\n", 
       "                        Market             Names No_Stage_Amount  \\\n", 
       "0                        Cable     Epic-Sciences                   \n", 
       "1                 All Students  Apreso-Classroom                   \n", 
       "2  Bridging Online and Offline         Visualead                   \n", 
       "3              Food Processing           Onshift      $7,000,000   \n", 
       "4                            -    Xendex-Holding                   \n", 
       "5                     Software          filmloop                   \n", 
       "6                                    Mochi-Media                   \n", 
       "7                            -  SkyRecon-Systems                   \n", 
       "8                                     Lumos-Labs                   \n", 
       "9                  Blockchains            ROBLOX                   \n", 
       "\n", 
       "  No_Stage_Date                                              Pitch  \\\n", 
       "0                                                                    \n", 
       "1                                                                    \n", 
       "2                Effective and Secure Offline to Mobile experie...   \n", 
       "3  Feb  3, 2014                                                      \n", 
       "4                                                                    \n", 
       "5                                                                    \n", 
       "6                                                                    \n", 
       "7                                                                    \n", 
       "8                                              Creator of Lumosity   \n", 
       "9                            User-Generated Online Gaming Platform   \n", 
       "\n", 
       "  Seed_Amount     Seed_Date Series_A_Amount Series_A_Date Series_B_Amount  \\\n", 
       "0                                                             $13,000,000   \n", 
       "1                                                             $15,000,000   \n", 
       "2    $750,000  Mar 25, 2012      $1,600,000  Aug 15, 2013         Unknown   \n", 
       "3                                                              $3,000,000   \n", 
       "4                                   Unknown  Jun 25, 2008      $3,500,000   \n", 
       "5                                $5,600,000  Feb  1, 2005      $7,000,000   \n", 
       "6                                $4,000,000  Mar 12, 2008     $10,000,000   \n", 
       "7                                $3,730,000  Sep 12, 2005      $6,500,000   \n", 
       "8    $450,000  Jun 11, 2007      $3,100,000  Jun  3, 2008                   \n", 
       "9                                $2,200,000  Aug 14, 2009      $4,000,000   \n", 
       "\n", 
       "  Series_B_Date Series_C_Amount Series_C_Date Series_D_Amount Series_D_Date  \\\n", 
       "0  Nov 13, 2012     $30,000,000  Jul 30, 2014                                 \n", 
       "1  Oct 14, 2008                                                               \n", 
       "2  Jan 20, 2015                                                               \n", 
       "3  Feb  2, 2012                                                               \n", 
       "4  Nov 30, 2009                                                               \n", 
       "5  May  1, 2006                                                               \n", 
       "6  Jun 18, 2008                                                               \n", 
       "7  Mar 12, 2007                                                               \n", 
       "8                   $32,500,000  Jun 16, 2011     $31,500,000  Aug 22, 2012   \n", 
       "9  Jun 14, 2011                                                               \n", 
       "\n", 
       "      Stage  \n", 
       "0  Series C  \n", 
       "1  Series B  \n", 
       "2  Series B  \n", 
       "3  Series C  \n", 
       "4  Series A  \n", 
       "5  Series A  \n", 
       "6            \n", 
       "7  Series A  \n", 
       "8            \n", 
       "9  Series A  "
      ], 
      "text/html": [
       "<div>\n", 
       "<table border=\"1\" class=\"dataframe\">\n", 
       "  <thead>\n", 
       "    <tr style=\"text-align: right;\">\n", 
       "      <th></th>\n", 
       "      <th>Description</th>\n", 
       "      <th>Market</th>\n", 
       "      <th>Names</th>\n", 
       "      <th>No_Stage_Amount</th>\n", 
       "      <th>No_Stage_Date</th>\n", 
       "      <th>Pitch</th>\n", 
       "      <th>Seed_Amount</th>\n", 
       "      <th>Seed_Date</th>\n", 
       "      <th>Series_A_Amount</th>\n", 
       "      <th>Series_A_Date</th>\n", 
       "      <th>Series_B_Amount</th>\n", 
       "      <th>Series_B_Date</th>\n", 
       "      <th>Series_C_Amount</th>\n", 
       "      <th>Series_C_Date</th>\n", 
       "      <th>Series_D_Amount</th>\n", 
       "      <th>Series_D_Date</th>\n", 
       "      <th>Stage</th>\n", 
       "    </tr>\n", 
       "  </thead>\n", 
       "  <tbody>\n", 
       "    <tr>\n", 
       "      <th>0</th>\n", 
       "      <td></td>\n", 
       "      <td>Cable</td>\n", 
       "      <td>Epic-Sciences</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$13,000,000</td>\n", 
       "      <td>Nov 13, 2012</td>\n", 
       "      <td>$30,000,000</td>\n", 
       "      <td>Jul 30, 2014</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series C</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>1</th>\n", 
       "      <td></td>\n", 
       "      <td>All Students</td>\n", 
       "      <td>Apreso-Classroom</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$15,000,000</td>\n", 
       "      <td>Oct 14, 2008</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series B</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>2</th>\n", 
       "      <td>Visualead (\u89c6\u89c9\u7801) creates better interactions be...</td>\n", 
       "      <td>Bridging Online and Offline</td>\n", 
       "      <td>Visualead</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Effective and Secure Offline to Mobile experie...</td>\n", 
       "      <td>$750,000</td>\n", 
       "      <td>Mar 25, 2012</td>\n", 
       "      <td>$1,600,000</td>\n", 
       "      <td>Aug 15, 2013</td>\n", 
       "      <td>Unknown</td>\n", 
       "      <td>Jan 20, 2015</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series B</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>3</th>\n", 
       "      <td></td>\n", 
       "      <td>Food Processing</td>\n", 
       "      <td>Onshift</td>\n", 
       "      <td>$7,000,000</td>\n", 
       "      <td>Feb  3, 2014</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$3,000,000</td>\n", 
       "      <td>Feb  2, 2012</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series C</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>4</th>\n", 
       "      <td></td>\n", 
       "      <td>-</td>\n", 
       "      <td>Xendex-Holding</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Unknown</td>\n", 
       "      <td>Jun 25, 2008</td>\n", 
       "      <td>$3,500,000</td>\n", 
       "      <td>Nov 30, 2009</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series A</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>5</th>\n", 
       "      <td>Palo Alto-based FilmLoop has reportedly layed ...</td>\n", 
       "      <td>Software</td>\n", 
       "      <td>filmloop</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$5,600,000</td>\n", 
       "      <td>Feb  1, 2005</td>\n", 
       "      <td>$7,000,000</td>\n", 
       "      <td>May  1, 2006</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series A</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>6</th>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Mochi-Media</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$4,000,000</td>\n", 
       "      <td>Mar 12, 2008</td>\n", 
       "      <td>$10,000,000</td>\n", 
       "      <td>Jun 18, 2008</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>7</th>\n", 
       "      <td></td>\n", 
       "      <td>-</td>\n", 
       "      <td>SkyRecon-Systems</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$3,730,000</td>\n", 
       "      <td>Sep 12, 2005</td>\n", 
       "      <td>$6,500,000</td>\n", 
       "      <td>Mar 12, 2007</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series A</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>8</th>\n", 
       "      <td>Challenge your brain with games designed by ne...</td>\n", 
       "      <td></td>\n", 
       "      <td>Lumos-Labs</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Creator of Lumosity</td>\n", 
       "      <td>$450,000</td>\n", 
       "      <td>Jun 11, 2007</td>\n", 
       "      <td>$3,100,000</td>\n", 
       "      <td>Jun  3, 2008</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$32,500,000</td>\n", 
       "      <td>Jun 16, 2011</td>\n", 
       "      <td>$31,500,000</td>\n", 
       "      <td>Aug 22, 2012</td>\n", 
       "      <td></td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>9</th>\n", 
       "      <td>ROBLOX is a comprehensive 3D creation, publish...</td>\n", 
       "      <td>Blockchains</td>\n", 
       "      <td>ROBLOX</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>User-Generated Online Gaming Platform</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$2,200,000</td>\n", 
       "      <td>Aug 14, 2009</td>\n", 
       "      <td>$4,000,000</td>\n", 
       "      <td>Jun 14, 2011</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series A</td>\n", 
       "    </tr>\n", 
       "  </tbody>\n", 
       "</table>\n", 
       "</div>"
      ]
     }, 
     "metadata": {}
    }
   ], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "execution_count": null, 
   "cell_type": "code", 
   "source": [], 
   "outputs": [], 
   "metadata": {
    "collapsed": true
   }
  }, 
  {
   "execution_count": null, 
   "cell_type": "code", 
   "source": [
    "from bs4 import BeautifulSoup\n", 
    "import urllib2\n", 
    "import urllib\n", 
    "import json\n", 
    "import csv\n", 
    "import time\n", 
    "import pickle\n", 
    "\n", 
    "request_headers = {\n", 
    "\"Connection\": \"keep-alive\",\n", 
    "\"Content-Length\": \"18\",\n", 
    "\"User-Agent\": \n", 
    "\"Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; .NET CLR 2.7.58687; SLCC2; Media Center PC 5.0; Zune 3.4; Tablet PC 3.6; InfoPath.3)\",\n", 
    "\"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n", 
    "\"Accept\": \"*/*\",\n", 
    "\"X-Requested-With\": \"XMLHttpRequest\",\n", 
    "\"Accept-Language\": \"en-US,en;q=0.8\",\n", 
    "\"Cookie\":\"multivariate_bot=false; D_SID=18.111.93.191:XQebItn+Xbbs4fxri7rWUENSpuNpcQ10POuRhCUaoqA; ahoy_visitor=85c0aa9d-5741-41b0-90a1-66c2407480de; _gat=1; _gat_newTracker=1; __qca=P0-280926842-1448694800387; __uvt=; amplitude_idcrunchbase.com=eyJkZXZpY2VJZCI6ImZlMjZjYmRmLTBjOTMtNGRhYy04ZmFlLTAyMjA1N2M0MzE1ZiIsInVzZXJJZCI6bnVsbH0=; _ga=GA1.2.961691226.1448694800; D_PID=C2974EEC-C295-3B19-881B-3987D348B229; D_IID=A7BBC9FB-58FB-3614-BC42-DC78B9DE46E3; D_UID=176CC3F7-AB55-33C4-934C-F4E77DFD0092; D_HID=3oV+ttwuR6fu7G+eqiUjkdE6kogcj3jL6jqRRPj1Gsw; s_pers=%20s_fid%3D76E928CEE4BFCC75-18BBFE4C3FC0792F%7C1511853228786%3B%20s_getnr%3D1448694828797-New%7C1511766828797%3B%20s_nrgvo%3DNew%7C1511766828800%3B; s_sess=%20s_cc%3Dtrue%3B%20s_sq%3D%3B; uvts=3rLFEsKv57hLKgqX; ahoy_visit=3bfd8d5a-8f74-44ba-b962-9e3ec8223f7e; RT=sl=10&ss=1448694798233&tt=10870&obo=1&bcn=%2F%2F36cc248b.mpstat.us%2F&sh=1448695098621%3D10%3A1%3A10870%2C1448694830134%3D9%3A1%3A10840%2C1448694829092%3D8%3A1%3A10432%2C1448694826377%3D7%3A1%3A8406%2C1448694825821%3D6%3A1%3A8036&dm=crunchbase.com&si=60d1ff9b-5c80-4211-9ed3-061f33fd2b83&r=https%3A%2F%2Fwww.crunchbase.com%2Forganization%2Friskiq&ul=1448695104730\"\n", 
    "}\n", 
    "\n", 
    "\n", 
    "cb_request_headers = {\"Host\": \"www.crunchbase.com\",\n", 
    "\"Connection\": \"keep-alive\",\n", 
    "\"Cache-Control\": \"max-age=0\",\n", 
    "\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n", 
    "\"Upgrade-Insecure-Requests\": \"1\",\n", 
    "\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36\",\n", 
    "\"DNT\": \"1\",\n", 
    "\"Referer\": \"https://www.crunchbase.com/organization/riskiq\",\n", 
    "\"Accept-Encoding\": \"gzip, deflate, sdch\",\n", 
    "\"Accept-Language\": \"en-US,en;q=0.8\"}\n", 
    "\n", 
    "link = \"https://www.crunchbase.com/organization/riskiq\"\n", 
    "request = urllib2.Request(link, headers=cb_request_headers)\n", 
    "contents = urllib.urlopen(link).read()"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": true
   }
  }, 
  {
   "source": [
    "We creates headers the proper headers for accessing the data from Crunchbase and try to make a request. However, after running, this attempt to scrape the data does not work because of antiscraping software. "
   ], 
   "cell_type": "markdown", 
   "metadata": {}
  }, 
  {
   "execution_count": null, 
   "cell_type": "code", 
   "source": [
    "from selenium import webdriver\n", 
    "from selenium.webdriver.support.wait import WebDriverWait\n", 
    "from selenium.webdriver.support import expected_conditions as EC\n", 
    "from selenium.webdriver.common.by import By\n", 
    "\n", 
    "#cb_data = {}\n", 
    "start = time.time()\n", 
    "org_list = [\"riskiq\", \"pixalate\"]\n", 
    "num_orgs = len(org_list)\n", 
    "browser = webdriver.Firefox()\n", 
    "#browser = webdriver.Chrome('/Users/candokevin/Downloads/chromedriver')\n", 
    "\n", 
    "for i in range(num_orgs):\n", 
    "    org = org_list[i]\n", 
    "    uri = \"https://www.crunchbase.com/organization/\" + org\n", 
    "    browser.get(uri)\n", 
    "    wait = WebDriverWait(browser, 30)\n", 
    "    element = wait.until(EC.element_to_be_clickable((By.ID,'anchor-title')))\n", 
    "    html_source = browser.page_source\n", 
    "    soup = BeautifulSoup(html_source, \"lxml\")\n", 
    "    fund_table = soup.find_all(\"div\", class_=\"funding_rounds\")\n", 
    "    fund_table_rows = fund_table[0].find_all(\"tr\")    \n", 
    "    description = soup.find_all(\"div\", class_=\"description-ellipsis\")\n", 
    "    cb_data[org] = (description[0].text, [fund_table_rows[i].text for i in range(1, len(fund_table_rows))])\n", 
    "    \n", 
    "    # Timing and saving code\n", 
    "    if i % 1 == 0:\n", 
    "        mins = (time.time() - start) / 60\n", 
    "        print 'Percent progress ' + str(100 * float(i) / num_orgs) + ' running for ' + str(mins) + ' mins'\n", 
    "        backup(cb_data, i)\n", 
    "    time.sleep(5)\n", 
    "        \n", 
    "browser.quit()"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": true
   }
  }, 
  {
   "source": [
    "Also attempted to run scrapers using the external library Selenium. However, Crunchbase has anti-scraping software that prevents you from using these types of methods. We requested access to the Crunchbase API, but never heard back. Consequently, we used Angel data instead."
   ], 
   "cell_type": "markdown", 
   "metadata": {}
  }, 
  {
   "execution_count": null, 
   "cell_type": "code", 
   "source": [], 
   "outputs": [], 
   "metadata": {
    "collapsed": true
   }
  }, 
  {
   "execution_count": 3, 
   "cell_type": "code", 
   "source": [
    "%matplotlib inline\n", 
    "from bs4 import BeautifulSoup\n", 
    "import urllib2\n", 
    "import urllib\n", 
    "import json\n", 
    "import csv\n", 
    "import time\n", 
    "import pickle\n", 
    "import pandas as pd\n", 
    "import numpy as np\n", 
    "import scipy as sp\n", 
    "import matplotlib as mpl\n", 
    "import matplotlib.cm as cm\n", 
    "import matplotlib.pyplot as plt\n", 
    "import pandas as pd\n", 
    "pd.set_option('display.width', 500)\n", 
    "pd.set_option('display.max_columns', 100)\n", 
    "pd.set_option('display.notebook_repr_html', True)\n", 
    "import seaborn as sns\n", 
    "import sys\n", 
    "import os\n", 
    "import time\n", 
    "sns.set_style(\"whitegrid\")\n", 
    "sns.set_context(\"poster\")"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": true
   }
  }, 
  {
   "execution_count": 2, 
   "cell_type": "code", 
   "source": [
    "def load_obj(name):\n", 
    "    with open(name + '.pkl', 'rb') as f:\n", 
    "        return pickle.load(f)\n", 
    "    \n", 
    "def merge_d(x, y):\n", 
    "    z = x.copy()\n", 
    "    z.update(y)\n", 
    "    return z\n", 
    "\n", 
    "def flatten_data(t_data):\n", 
    "    t_data_f= {}\n", 
    "    for key in t_data.keys():\n", 
    "        for key2 in t_data[key].keys():\n", 
    "            t_data_f[key + '_' + key2] = t_data[key][key2]\n", 
    "    return t_data_f\n", 
    "\n", 
    "twit_data = flatten_data(load_obj('twit_data1'))\n", 
    "t_data_num = 1\n", 
    "\n", 
    "def backup(obj, t_data_num = t_data_num):\n", 
    "    name = \"t_df\" + str(t_data_num)\n", 
    "    with open(name + '.pkl', 'wb') as f:\n", 
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": true
   }
  }, 
  {
   "source": [
    "We now want to do some data wrangling to aggregate all the data from the Tweets. We want to get information about the tweet text, the number of likes, the number of retweets, names, and href. Later on, we can extract more analytics about these types of interactions."
   ], 
   "cell_type": "markdown", 
   "metadata": {}
  }, 
  {
   "execution_count": 12, 
   "cell_type": "code", 
   "source": [
    "company_l = []\n", 
    "series_l = []\n", 
    "text_l = [] \n", 
    "time_l = []\n", 
    "retweets_l = []\n", 
    "likes_l = []\n", 
    "name_l = []\n", 
    "href_l = []\n", 
    "errors = []\n", 
    "max_ind = len(twit_data.keys())\n", 
    "start = time.time()\n", 
    "\n", 
    "for i in range(max_ind):    \n", 
    "    \n", 
    "    # Timing code and backup code\n", 
    "    if i % 50 == 0:\n", 
    "        mins = (time.time() - start) / 60\n", 
    "        print 'Percent progress ' + str(100.0 * i / max_ind) + ' running for ' + str(mins) + ' mins'          \n", 
    "        data_backup = {'Company': company_l, 'Series': series_l, 'Text': text_l, 'Time':time_l, 'Retweets':retweets_l, 'Likes':likes_l, 'Name':name_l, 'Href':href_l}\n", 
    "        backup(data_backup)\n", 
    "    \n", 
    "    # Finding the series of the data\n", 
    "    company_series = twit_data.keys()[i]\n", 
    "    ind = company_series[:company_series.rfind(\"_\")].rfind(\"_\")\n", 
    "    company = company_series[:ind]\n", 
    "    series = company_series[ind:]\n", 
    "    backup({'Company': company_l, 'Series': series_l, 'Text': text_l, 'Time':time_l, 'Retweets':retweets_l, 'Likes':likes_l, 'Name':name_l, 'Href':href_l})\n", 
    "    \n", 
    "    \n", 
    "    # Loop through each copmany and series pair and extract relevant information\n", 
    "    for tweet in twit_data[company_series]:\n", 
    "        try:\n", 
    "            # Searching\n", 
    "            soup = BeautifulSoup(tweet, 'lxml')\n", 
    "            actions = soup.find_all('div', class_='ProfileTweet-actionCountList')[0]\n", 
    "            text = soup.find_all('p', class_ = 'TweetTextSize')[0].text\n", 
    "            times = soup.find_all('a', class_ = 'tweet-timestamp')[0].text\n", 
    "            retweets = actions.find_all('span', class_='ProfileTweet-actionCount')[0].text.strip()\n", 
    "            likes = actions.find_all('span', class_='ProfileTweet-actionCount')[1].text.strip()\n", 
    "            name = soup.find_all('strong', class_='fullname')[0].text\n", 
    "            href = soup.find_all('a', class_='account-group')[0]['href']\n", 
    "            \n", 
    "            # Storing\n", 
    "            company_l.append(company)\n", 
    "            series_l.append(series)\n", 
    "            text_l.append(text)\n", 
    "            time_l.append(times)\n", 
    "            retweets_l.append(retweets)\n", 
    "            likes_l.append(likes)\n", 
    "            name_l.append(name)\n", 
    "            href_l.append(href)\n", 
    "            \n", 
    "        # Only listen for keyboard exceptions\n", 
    "        except KeyboardInterrupt:\n", 
    "            try:\n", 
    "                sys.exit(0)\n", 
    "            except SystemExit:\n", 
    "                os._exit(0) \n", 
    "        except:\n", 
    "            errors.append(tweet)"
   ], 
   "outputs": [
    {
     "output_type": "stream", 
     "name": "stdout", 
     "text": [
      "Percent progress 0.0 running for 5.08666038513e-05 mins\n", 
      "Percent progress 5.0 running for 0.929983933767 mins\n", 
      "Percent progress 10.0 running for 2.19964901606 mins\n", 
      "Percent progress 15.0 running for 3.53876201709 mins\n", 
      "Percent progress 20.0 running for 4.88092761834 mins\n", 
      "Percent progress 25.0 running for 6.11316250165 mins\n", 
      "Percent progress 30.0 running for 7.68281498353 mins\n", 
      "Percent progress 35.0 running for 9.68449503183 mins\n", 
      "Percent progress 40.0 running for 11.6382258654 mins\n", 
      "Percent progress 45.0 running for 13.2810905496 mins\n", 
      "Percent progress 50.0 running for 15.5552463651 mins\n", 
      "Percent progress 55.0 running for 17.8359643817 mins\n", 
      "Percent progress 60.0 running for 20.021214668 mins\n", 
      "Percent progress 65.0 running for 22.598205018 mins\n", 
      "Percent progress 70.0 running for 25.0689711491 mins\n", 
      "Percent progress 75.0 running for 28.2786712845 mins\n", 
      "Percent progress 80.0 running for 31.1675331672 mins\n", 
      "Percent progress 85.0 running for 34.0141220649 mins\n", 
      "Percent progress 90.0 running for 37.2621017337 mins\n", 
      "Percent progress 95.0 running for 40.6350143154 mins\n"
     ]
    }
   ], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "source": [
    "After extracting all tweets from the HTML page, we now want to try to generate features that we can regress on. We save the tweets to a file, and then extract features from all of these tweets."
   ], 
   "cell_type": "markdown", 
   "metadata": {}
  }, 
  {
   "execution_count": 5, 
   "cell_type": "code", 
   "source": [
    "tweets = pd.read_csv(open(\"../tweets/tweets.csv\", 'rU'), encoding='utf-8', engine='c')\n", 
    "tweets_translated = pd.read_csv(open(\"../startups/translatedTweets.csv\", 'rU'), encoding='utf-8', engine='c')\n", 
    "tweets_translated.head()"
   ], 
   "outputs": [
    {
     "output_type": "stream", 
     "name": "stderr", 
     "text": [
      "/Users/candokevin/anaconda/lib/python2.7/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n", 
      "  data = self._reader.read(nrows)\n"
     ]
    }, 
    {
     "execution_count": 5, 
     "output_type": "execute_result", 
     "data": {
      "text/plain": [
       "   Unnamed: 0 Unnamed: 0.1    Company           Href    Likes              Name    Retweets     Series                                               Text         Time\n", 
       "0           0            0  Occipital  /yehyehgluglu  0 likes        Maria Melo  0 retweets  _Series_A  @rubaums2 mira in the occipital and frontal to...  14 Jul 2011\n", 
       "1           1            2  Occipital  /ArturoMisifu  0 likes    Arturo Quijano  0 retweets  _Series_A  at the height of the occipital head - hurts if...  14 Jul 2011\n", 
       "2           2            5  Occipital     /victorcab  0 likes  Victor Caballero  0 retweets  _Series_A  Tripod \u2013 Timer for 360 Views \u2013 iPhone? : http:...  14 Jul 2011\n", 
       "3           3            7  Occipital   /electroniko  0 likes    MIGUEL NEGRETE  0 retweets  _Series_A  Neurona, glia, axon myelin, parietal, temporal...  14 Jul 2011\n", 
       "4           4            8  Occipital    /nomina_bot  0 likes              \u4f53\u91ce\u30df\u30ca  0 retweets  _Series_A  Greater occipital nerve:nervus occipitalis maj...  13 Jul 2011"
      ], 
      "text/html": [
       "<div>\n", 
       "<table border=\"1\" class=\"dataframe\">\n", 
       "  <thead>\n", 
       "    <tr style=\"text-align: right;\">\n", 
       "      <th></th>\n", 
       "      <th>Unnamed: 0</th>\n", 
       "      <th>Unnamed: 0.1</th>\n", 
       "      <th>Company</th>\n", 
       "      <th>Href</th>\n", 
       "      <th>Likes</th>\n", 
       "      <th>Name</th>\n", 
       "      <th>Retweets</th>\n", 
       "      <th>Series</th>\n", 
       "      <th>Text</th>\n", 
       "      <th>Time</th>\n", 
       "    </tr>\n", 
       "  </thead>\n", 
       "  <tbody>\n", 
       "    <tr>\n", 
       "      <th>0</th>\n", 
       "      <td>0</td>\n", 
       "      <td>0</td>\n", 
       "      <td>Occipital</td>\n", 
       "      <td>/yehyehgluglu</td>\n", 
       "      <td>0 likes</td>\n", 
       "      <td>Maria Melo</td>\n", 
       "      <td>0 retweets</td>\n", 
       "      <td>_Series_A</td>\n", 
       "      <td>@rubaums2 mira in the occipital and frontal to...</td>\n", 
       "      <td>14 Jul 2011</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>1</th>\n", 
       "      <td>1</td>\n", 
       "      <td>2</td>\n", 
       "      <td>Occipital</td>\n", 
       "      <td>/ArturoMisifu</td>\n", 
       "      <td>0 likes</td>\n", 
       "      <td>Arturo Quijano</td>\n", 
       "      <td>0 retweets</td>\n", 
       "      <td>_Series_A</td>\n", 
       "      <td>at the height of the occipital head - hurts if...</td>\n", 
       "      <td>14 Jul 2011</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>2</th>\n", 
       "      <td>2</td>\n", 
       "      <td>5</td>\n", 
       "      <td>Occipital</td>\n", 
       "      <td>/victorcab</td>\n", 
       "      <td>0 likes</td>\n", 
       "      <td>Victor Caballero</td>\n", 
       "      <td>0 retweets</td>\n", 
       "      <td>_Series_A</td>\n", 
       "      <td>Tripod \u2013 Timer for 360 Views \u2013 iPhone? : http:...</td>\n", 
       "      <td>14 Jul 2011</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>3</th>\n", 
       "      <td>3</td>\n", 
       "      <td>7</td>\n", 
       "      <td>Occipital</td>\n", 
       "      <td>/electroniko</td>\n", 
       "      <td>0 likes</td>\n", 
       "      <td>MIGUEL NEGRETE</td>\n", 
       "      <td>0 retweets</td>\n", 
       "      <td>_Series_A</td>\n", 
       "      <td>Neurona, glia, axon myelin, parietal, temporal...</td>\n", 
       "      <td>14 Jul 2011</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>4</th>\n", 
       "      <td>4</td>\n", 
       "      <td>8</td>\n", 
       "      <td>Occipital</td>\n", 
       "      <td>/nomina_bot</td>\n", 
       "      <td>0 likes</td>\n", 
       "      <td>\u4f53\u91ce\u30df\u30ca</td>\n", 
       "      <td>0 retweets</td>\n", 
       "      <td>_Series_A</td>\n", 
       "      <td>Greater occipital nerve:nervus occipitalis maj...</td>\n", 
       "      <td>13 Jul 2011</td>\n", 
       "    </tr>\n", 
       "  </tbody>\n", 
       "</table>\n", 
       "</div>"
      ]
     }, 
     "metadata": {}
    }
   ], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "source": [
    "We only take tweets that relate to companies that have 150 or more tweets. We also want to calculate the average number of days it took to reach 200 tweets. "
   ], 
   "cell_type": "markdown", 
   "metadata": {}
  }, 
  {
   "execution_count": null, 
   "cell_type": "code", 
   "source": [
    "# Calculating relative dates based off of dates like Apr, 5 2015. We can use this later\n", 
    "# for calculating average number of tweets per day.\n", 
    "months = {'Jan':1, 'Feb':2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7, 'Aug':8, 'Sep':9, 'Oct':10, 'Nov':11, 'Dec':12}\n", 
    "time_sub = []\n", 
    "for row in tweets.iterrows():\n", 
    "    if type(row[1]['Time']) != unicode:\n", 
    "        time_sub.append(0)\n", 
    "    elif len(row[1]['Time'].split(' ')) == 3:\n", 
    "        if row[1]['Time'].split(' ')[1] in months.keys():        \n", 
    "            time_sub.append(int(row[1]['Time'].split(' ')[2]) * 365 + months[row[1]['Time'].split(' ')[1]] * 30 + int(row[1]['Time'].split(' ')[0]))\n", 
    "        else:\n", 
    "            time_sub.append(0)\n", 
    "    else:\n", 
    "        time_sub.append(0)\n", 
    "        \n", 
    "tweets['Date_Num'] = time_sub\n", 
    "tweets = tweets[tweets['Date_Num'] != 0]\n", 
    "\n", 
    "valid_data = []\n", 
    "for val in zip(list((tweets.groupby(['Company', 'Series']).size() > 150).index), list((tweets.groupby(['Company', 'Series']).size() > 150).values)):\n", 
    "    if val[1]:\n", 
    "        valid_data.append(val[0])\n", 
    "        \n", 
    "# We also only filter the tweets based off of whether or not there was 150 tweets in the past\n", 
    "valid_tweets = []\n", 
    "for valid_pair in valid_data:\n", 
    "    company = valid_pair[0]\n", 
    "    series = valid_pair[1]\n", 
    "    match_company = tweets[tweets['Company'] == company]\n", 
    "    valid_tweets.append(match_company[match_company['Series'] == series])\n"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "execution_count": 69, 
   "cell_type": "code", 
   "source": [
    "# We are now incorporate the translated tweets that Roger generated\n", 
    "valid_tweets_pd = pd.concat(valid_tweets)\n", 
    "for row in tweets_translated.iterrows():\n", 
    "    company = row[1]['Company']\n", 
    "    href = row[1]['Href']\n", 
    "    time = row[1]['Time']\n", 
    "\n", 
    "    match_comp = valid_tweets_pd[valid_tweets_pd['Company'] == company]\n", 
    "    match_href = match_comp[match_comp['Href'] == href]\n", 
    "    match_time = match_href[match_href['Time'] == time]\n", 
    "    \n", 
    "    res = list(match_time.index)\n", 
    "    if len(res) == 1:\n", 
    "        index = res[0]\n", 
    "        valid_tweets_pd.set_value(index, 'Text', row[1].Text)"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "execution_count": 71, 
   "cell_type": "code", 
   "source": [
    "valid_tweets_pd.to_csv('valid_tweets.csv', encoding='utf-8')"
   ], 
   "outputs": [], 
   "metadata": {
    "scrolled": true, 
    "collapsed": false
   }
  }, 
  {
   "execution_count": 68, 
   "cell_type": "code", 
   "source": [
    "len(tweets_translated)"
   ], 
   "outputs": [
    {
     "execution_count": 68, 
     "output_type": "execute_result", 
     "data": {
      "text/plain": [
       "198201"
      ]
     }, 
     "metadata": {}
    }
   ], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "source": [
    "It seems that the total number of tweets is now 2/3 of what it used to be. It seems reasonable to drop this many tweets."
   ], 
   "cell_type": "markdown", 
   "metadata": {}
  }, 
  {
   "execution_count": null, 
   "cell_type": "code", 
   "source": [
    "valid_tweets_pd = pd.concat(valid_tweets)\n", 
    "valid_tweets_pd['Likes'] = valid_tweets_pd.apply(lambda row: int(row['Likes'][0]), axis=1)\n", 
    "valid_tweets_pd['Retweets'] = valid_tweets_pd.apply(lambda row: int(row['Retweets'][0]), axis=1)"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": true
   }
  }, 
  {
   "source": [
    "Now we want to extract relevant features like the number of likes, retweets, and other relevant features for each company funding round pairing. "
   ], 
   "cell_type": "markdown", 
   "metadata": {}
  }, 
  {
   "execution_count": 224, 
   "cell_type": "code", 
   "source": [
    "# Calculate average tweets\n", 
    "days = valid_tweets_pd.groupby(['Company', 'Series'])['Date_Num'].max() - valid_tweets_pd.groupby(['Company', 'Series'])['Date_Num'].min()\n", 
    "tweets = valid_tweets_pd.groupby(['Company', 'Series']).size()\n", 
    "avg_tweets = tweets / days\n", 
    "\n", 
    "# Calculate total likes\n", 
    "total_likes= valid_tweets_pd.groupby(['Company', 'Series'])['Likes'].sum()\n", 
    "\n", 
    "# Calculate total retweets\n", 
    "total_retweets = valid_tweets_pd.groupby(['Company', 'Series'])['Retweets'].sum()\n", 
    "companies = [val[0] for val in list(tweets.index)]\n", 
    "series = [val[1] for val in list(tweets.index)]\n", 
    "\n", 
    "# Calculate all features\n", 
    "tweet_features = pd.DataFrame({'Index': range(1, 1+len(days)), 'Company':companies, 'Series':series, 'Total_Likes': total_likes, 'Total_Retweets': total_retweets, 'Avg_Tweets': avg_tweets})\n", 
    "tweet_features.index = range(1, 1+len(days))\n", 
    "\n", 
    "# Open old funding data\n", 
    "funding_df=pd.read_csv(\"funding_collapsed.csv\")\n", 
    "funding_df = funding_df.drop(['Unnamed: 0'], 1)\n", 
    "funding_df.rename(columns={'Names':'Company', 'Series_Type':'Series'}, inplace=True)\n", 
    "\n", 
    "# Merge the tweet features with the funding data\n", 
    "regress_features = pd.merge(tweet_features, funding_df, how='left', on=['Company', 'Series'])\n", 
    "regress_features = regress_features.drop('Index', 1)\n", 
    "regress_features = regress_features[([type(amount) == str for amount in list(regress_features.Series_Amount)])]\n", 
    "regress_features['Series_Amount'] = regress_features.apply(lambda row: int(row['Series_Amount'][1:].replace(',','')), axis=1)\n", 
    "regress_features.to_csv('regress_features.csv')"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "execution_count": 4, 
   "cell_type": "code", 
   "source": [
    "%matplotlib inline\n", 
    "from bs4 import BeautifulSoup\n", 
    "import urllib2\n", 
    "import urllib\n", 
    "import json\n", 
    "import csv\n", 
    "import time\n", 
    "import pickle\n", 
    "import pandas as pd\n", 
    "import numpy as np\n", 
    "import scipy as sp\n", 
    "import matplotlib as mpl\n", 
    "import matplotlib.cm as cm\n", 
    "import matplotlib.pyplot as plt\n", 
    "import pandas as pd\n", 
    "pd.set_option('display.width', 500)\n", 
    "pd.set_option('display.max_columns', 100)\n", 
    "pd.set_option('display.notebook_repr_html', True)\n", 
    "import seaborn as sns\n", 
    "import sys\n", 
    "sns.set_style(\"whitegrid\")\n", 
    "sns.set_context(\"poster\")\n", 
    "\n", 
    "from selenium import webdriver\n", 
    "from selenium.webdriver.support.wait import WebDriverWait\n", 
    "from selenium.webdriver.support import expected_conditions as EC\n", 
    "from selenium.webdriver.common.by import By"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": true
   }
  }, 
  {
   "source": [
    "Code for backing up any data that we calculate. We want to make sure that if there is some reason why the twitter data stops being scraped, we save all data scraped thus far."
   ], 
   "cell_type": "markdown", 
   "metadata": {}
  }, 
  {
   "execution_count": 5, 
   "cell_type": "code", 
   "source": [
    "def backup(obj, info):\n", 
    "    name = \"twit_data\" + str(info)\n", 
    "    with open(name + '.pkl', 'wb') as f:\n", 
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n", 
    "        \n", 
    "def load_obj(name):\n", 
    "    with open(name + '.pkl', 'rb') as f:\n", 
    "        return pickle.load(f)"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": true
   }
  }, 
  {
   "execution_count": 6, 
   "cell_type": "code", 
   "source": [
    "funding_df=pd.read_csv(\"funding.csv\")\n", 
    "funding_df.fillna('', inplace=True)\n", 
    "funding_df = funding_df.replace(['Unknown'], [''])\n", 
    "funding_df.head(15)"
   ], 
   "outputs": [
    {
     "execution_count": 6, 
     "output_type": "execute_result", 
     "data": {
      "text/plain": [
       "                                          Description                       Market              Names No_Stage_Amount No_Stage_Date                                              Pitch Seed_Amount     Seed_Date Series_A_Amount Series_A_Date Series_B_Amount Series_B_Date Series_C_Amount Series_C_Date Series_D_Amount Series_D_Date     Stage\n", 
       "0                                                                            Cable      Epic-Sciences                                                                                                                                              $13,000,000  Nov 13, 2012     $30,000,000  Jul 30, 2014                                Series C\n", 
       "1                                                                     All Students   Apreso-Classroom                                                                                                                                              $15,000,000  Oct 14, 2008                                                              Series B\n", 
       "2   Visualead (\u89c6\u89c9\u7801) creates better interactions be...  Bridging Online and Offline          Visualead                                Effective and Secure Offline to Mobile experie...    $750,000  Mar 25, 2012      $1,600,000  Aug 15, 2013                  Jan 20, 2015                                                              Series B\n", 
       "3                                                                  Food Processing            Onshift      $7,000,000  Feb  3, 2014                                                                                                                 $3,000,000  Feb  2, 2012                                                              Series C\n", 
       "4                                                                                -     Xendex-Holding                                                                                                                             Jun 25, 2008      $3,500,000  Nov 30, 2009                                                              Series A\n", 
       "5   Palo Alto-based FilmLoop has reportedly layed ...                     Software           filmloop                                                                                                                 $5,600,000  Feb  1, 2005      $7,000,000  May  1, 2006                                                              Series A\n", 
       "6                                                                                         Mochi-Media                                                                                                                 $4,000,000  Mar 12, 2008     $10,000,000  Jun 18, 2008                                                                      \n", 
       "7                                                                                -   SkyRecon-Systems                                                                                                                 $3,730,000  Sep 12, 2005      $6,500,000  Mar 12, 2007                                                              Series A\n", 
       "8   Challenge your brain with games designed by ne...                                      Lumos-Labs                                                              Creator of Lumosity    $450,000  Jun 11, 2007      $3,100,000  Jun  3, 2008                                   $32,500,000  Jun 16, 2011     $31,500,000  Aug 22, 2012          \n", 
       "9   ROBLOX is a comprehensive 3D creation, publish...                  Blockchains             ROBLOX                                            User-Generated Online Gaming Platform                                $2,200,000  Aug 14, 2009      $4,000,000  Jun 14, 2011                                                              Series A\n", 
       "10  SendHub makes business communication fast and ...                          B2B            SendHub                                                Phone System for the Mobile World  $2,000,000  Apr 26, 2012      $3,000,000  Sep  6, 2013      $5,000,000  Nov 19, 2014                                                              Series A\n", 
       "11                                                                        Colleges  Health-Guru-Media                                                                                                                   $250,000  Jan  1, 2007                                    $3,200,000  Oct 21, 2009      $6,000,000  Jun 29, 2011  Series A\n", 
       "12                                                                     Advertising     Madhouse-Media                  Jan  1, 2013                                                                                                                 $2,700,000  Mar  1, 2007      $1,000,000  Oct  1, 2008      $5,000,000  Jun  1, 2010         -\n", 
       "13                                                                        Security          White-Sky      $7,500,000  Jun 18, 2012                                                                                   $5,000,000  Sep 26, 2006     $11,000,000  Sep 10, 2008                                                              Series B\n", 
       "14                                                                Mobile Analytics       Forus-Health                                                                                                                 $5,000,000  Apr 27, 2012      $8,400,000  Jan  9, 2014                                                              Series A"
      ], 
      "text/html": [
       "<div>\n", 
       "<table border=\"1\" class=\"dataframe\">\n", 
       "  <thead>\n", 
       "    <tr style=\"text-align: right;\">\n", 
       "      <th></th>\n", 
       "      <th>Description</th>\n", 
       "      <th>Market</th>\n", 
       "      <th>Names</th>\n", 
       "      <th>No_Stage_Amount</th>\n", 
       "      <th>No_Stage_Date</th>\n", 
       "      <th>Pitch</th>\n", 
       "      <th>Seed_Amount</th>\n", 
       "      <th>Seed_Date</th>\n", 
       "      <th>Series_A_Amount</th>\n", 
       "      <th>Series_A_Date</th>\n", 
       "      <th>Series_B_Amount</th>\n", 
       "      <th>Series_B_Date</th>\n", 
       "      <th>Series_C_Amount</th>\n", 
       "      <th>Series_C_Date</th>\n", 
       "      <th>Series_D_Amount</th>\n", 
       "      <th>Series_D_Date</th>\n", 
       "      <th>Stage</th>\n", 
       "    </tr>\n", 
       "  </thead>\n", 
       "  <tbody>\n", 
       "    <tr>\n", 
       "      <th>0</th>\n", 
       "      <td></td>\n", 
       "      <td>Cable</td>\n", 
       "      <td>Epic-Sciences</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$13,000,000</td>\n", 
       "      <td>Nov 13, 2012</td>\n", 
       "      <td>$30,000,000</td>\n", 
       "      <td>Jul 30, 2014</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series C</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>1</th>\n", 
       "      <td></td>\n", 
       "      <td>All Students</td>\n", 
       "      <td>Apreso-Classroom</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$15,000,000</td>\n", 
       "      <td>Oct 14, 2008</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series B</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>2</th>\n", 
       "      <td>Visualead (\u89c6\u89c9\u7801) creates better interactions be...</td>\n", 
       "      <td>Bridging Online and Offline</td>\n", 
       "      <td>Visualead</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Effective and Secure Offline to Mobile experie...</td>\n", 
       "      <td>$750,000</td>\n", 
       "      <td>Mar 25, 2012</td>\n", 
       "      <td>$1,600,000</td>\n", 
       "      <td>Aug 15, 2013</td>\n", 
       "      <td></td>\n", 
       "      <td>Jan 20, 2015</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series B</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>3</th>\n", 
       "      <td></td>\n", 
       "      <td>Food Processing</td>\n", 
       "      <td>Onshift</td>\n", 
       "      <td>$7,000,000</td>\n", 
       "      <td>Feb  3, 2014</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$3,000,000</td>\n", 
       "      <td>Feb  2, 2012</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series C</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>4</th>\n", 
       "      <td></td>\n", 
       "      <td>-</td>\n", 
       "      <td>Xendex-Holding</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Jun 25, 2008</td>\n", 
       "      <td>$3,500,000</td>\n", 
       "      <td>Nov 30, 2009</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series A</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>5</th>\n", 
       "      <td>Palo Alto-based FilmLoop has reportedly layed ...</td>\n", 
       "      <td>Software</td>\n", 
       "      <td>filmloop</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$5,600,000</td>\n", 
       "      <td>Feb  1, 2005</td>\n", 
       "      <td>$7,000,000</td>\n", 
       "      <td>May  1, 2006</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series A</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>6</th>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Mochi-Media</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$4,000,000</td>\n", 
       "      <td>Mar 12, 2008</td>\n", 
       "      <td>$10,000,000</td>\n", 
       "      <td>Jun 18, 2008</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>7</th>\n", 
       "      <td></td>\n", 
       "      <td>-</td>\n", 
       "      <td>SkyRecon-Systems</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$3,730,000</td>\n", 
       "      <td>Sep 12, 2005</td>\n", 
       "      <td>$6,500,000</td>\n", 
       "      <td>Mar 12, 2007</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series A</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>8</th>\n", 
       "      <td>Challenge your brain with games designed by ne...</td>\n", 
       "      <td></td>\n", 
       "      <td>Lumos-Labs</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Creator of Lumosity</td>\n", 
       "      <td>$450,000</td>\n", 
       "      <td>Jun 11, 2007</td>\n", 
       "      <td>$3,100,000</td>\n", 
       "      <td>Jun  3, 2008</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$32,500,000</td>\n", 
       "      <td>Jun 16, 2011</td>\n", 
       "      <td>$31,500,000</td>\n", 
       "      <td>Aug 22, 2012</td>\n", 
       "      <td></td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>9</th>\n", 
       "      <td>ROBLOX is a comprehensive 3D creation, publish...</td>\n", 
       "      <td>Blockchains</td>\n", 
       "      <td>ROBLOX</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>User-Generated Online Gaming Platform</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$2,200,000</td>\n", 
       "      <td>Aug 14, 2009</td>\n", 
       "      <td>$4,000,000</td>\n", 
       "      <td>Jun 14, 2011</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series A</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>10</th>\n", 
       "      <td>SendHub makes business communication fast and ...</td>\n", 
       "      <td>B2B</td>\n", 
       "      <td>SendHub</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Phone System for the Mobile World</td>\n", 
       "      <td>$2,000,000</td>\n", 
       "      <td>Apr 26, 2012</td>\n", 
       "      <td>$3,000,000</td>\n", 
       "      <td>Sep  6, 2013</td>\n", 
       "      <td>$5,000,000</td>\n", 
       "      <td>Nov 19, 2014</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series A</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>11</th>\n", 
       "      <td></td>\n", 
       "      <td>Colleges</td>\n", 
       "      <td>Health-Guru-Media</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$250,000</td>\n", 
       "      <td>Jan  1, 2007</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$3,200,000</td>\n", 
       "      <td>Oct 21, 2009</td>\n", 
       "      <td>$6,000,000</td>\n", 
       "      <td>Jun 29, 2011</td>\n", 
       "      <td>Series A</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>12</th>\n", 
       "      <td></td>\n", 
       "      <td>Advertising</td>\n", 
       "      <td>Madhouse-Media</td>\n", 
       "      <td></td>\n", 
       "      <td>Jan  1, 2013</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$2,700,000</td>\n", 
       "      <td>Mar  1, 2007</td>\n", 
       "      <td>$1,000,000</td>\n", 
       "      <td>Oct  1, 2008</td>\n", 
       "      <td>$5,000,000</td>\n", 
       "      <td>Jun  1, 2010</td>\n", 
       "      <td>-</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>13</th>\n", 
       "      <td></td>\n", 
       "      <td>Security</td>\n", 
       "      <td>White-Sky</td>\n", 
       "      <td>$7,500,000</td>\n", 
       "      <td>Jun 18, 2012</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$5,000,000</td>\n", 
       "      <td>Sep 26, 2006</td>\n", 
       "      <td>$11,000,000</td>\n", 
       "      <td>Sep 10, 2008</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series B</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>14</th>\n", 
       "      <td></td>\n", 
       "      <td>Mobile Analytics</td>\n", 
       "      <td>Forus-Health</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>$5,000,000</td>\n", 
       "      <td>Apr 27, 2012</td>\n", 
       "      <td>$8,400,000</td>\n", 
       "      <td>Jan  9, 2014</td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td></td>\n", 
       "      <td>Series A</td>\n", 
       "    </tr>\n", 
       "  </tbody>\n", 
       "</table>\n", 
       "</div>"
      ]
     }, 
     "metadata": {}
    }
   ], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "execution_count": 7, 
   "cell_type": "code", 
   "source": [
    "months = {'Jan':1, 'Feb':2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7, 'Aug':8, 'Sep':9, 'Oct':10, 'Nov':11, 'Dec':12}\n", 
    "def find_dates(date_str):\n", 
    "    if len(date_str) < 8:\n", 
    "        return None\n", 
    "    yr = date_str[-4:]\n", 
    "    mon_str = date_str[:3]\n", 
    "    mon_num = None\n", 
    "    for k in months.keys():\n", 
    "        if k == mon_str:\n", 
    "            mon_num = months[k]\n", 
    "    if not yr.isdigit() or mon_num is None:\n", 
    "        return None\n", 
    "    mon_num = (mon_num - 1) \n", 
    "    if mon_num == 0:\n", 
    "        mon_num = 12\n", 
    "    end_date = str(yr) + '-' + str(mon_num) + '-15'\n", 
    "    start_date = str(int(yr) - 10) + '-' + str(mon_num) + '-15'\n", 
    "    return (start_date, end_date)"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "execution_count": 8, 
   "cell_type": "code", 
   "source": [
    "series_A = funding_df[funding_df['Series_A_Amount'] != ''][['Names', 'Series_A_Amount', 'Series_A_Date']]\n", 
    "series_A.columns = ['Names', 'Series_Amount', 'Series_Date']\n", 
    "series_A['Series_Type'] = pd.Series('Series_A', index=series_A.index)\n", 
    "\n", 
    "series_B = funding_df[funding_df['Series_B_Amount'] != ''][['Names', 'Series_B_Amount', 'Series_B_Date']]\n", 
    "series_B.columns = ['Names', 'Series_Amount', 'Series_Date']\n", 
    "series_B['Series_Type'] = pd.Series('Series_B', index=series_B.index)\n", 
    "\n", 
    "series_C = funding_df[funding_df['Series_C_Amount'] != ''][['Names', 'Series_C_Amount', 'Series_C_Date']]\n", 
    "series_C.columns = ['Names', 'Series_Amount', 'Series_Date']\n", 
    "series_C['Series_Type'] = pd.Series('Series_C', index=series_C.index)\n", 
    "\n", 
    "series_D = funding_df[funding_df['Series_D_Amount'] != ''][['Names', 'Series_D_Amount', 'Series_D_Date']]\n", 
    "series_D.columns = ['Names', 'Series_Amount', 'Series_Date']\n", 
    "series_D['Series_Type'] = pd.Series('Series_D', index=series_D.index)\n", 
    "\n", 
    "funding_collapsed = pd.concat([series_A, series_B, series_C, series_D])\n", 
    "funding_collapsed.head()"
   ], 
   "outputs": [
    {
     "execution_count": 8, 
     "output_type": "execute_result", 
     "data": {
      "text/plain": [
       "              Names Series_Amount   Series_Date Series_Type\n", 
       "2         Visualead    $1,600,000  Aug 15, 2013    Series_A\n", 
       "5          filmloop    $5,600,000  Feb  1, 2005    Series_A\n", 
       "6       Mochi-Media    $4,000,000  Mar 12, 2008    Series_A\n", 
       "7  SkyRecon-Systems    $3,730,000  Sep 12, 2005    Series_A\n", 
       "8        Lumos-Labs    $3,100,000  Jun  3, 2008    Series_A"
      ], 
      "text/html": [
       "<div>\n", 
       "<table border=\"1\" class=\"dataframe\">\n", 
       "  <thead>\n", 
       "    <tr style=\"text-align: right;\">\n", 
       "      <th></th>\n", 
       "      <th>Names</th>\n", 
       "      <th>Series_Amount</th>\n", 
       "      <th>Series_Date</th>\n", 
       "      <th>Series_Type</th>\n", 
       "    </tr>\n", 
       "  </thead>\n", 
       "  <tbody>\n", 
       "    <tr>\n", 
       "      <th>2</th>\n", 
       "      <td>Visualead</td>\n", 
       "      <td>$1,600,000</td>\n", 
       "      <td>Aug 15, 2013</td>\n", 
       "      <td>Series_A</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>5</th>\n", 
       "      <td>filmloop</td>\n", 
       "      <td>$5,600,000</td>\n", 
       "      <td>Feb  1, 2005</td>\n", 
       "      <td>Series_A</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>6</th>\n", 
       "      <td>Mochi-Media</td>\n", 
       "      <td>$4,000,000</td>\n", 
       "      <td>Mar 12, 2008</td>\n", 
       "      <td>Series_A</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>7</th>\n", 
       "      <td>SkyRecon-Systems</td>\n", 
       "      <td>$3,730,000</td>\n", 
       "      <td>Sep 12, 2005</td>\n", 
       "      <td>Series_A</td>\n", 
       "    </tr>\n", 
       "    <tr>\n", 
       "      <th>8</th>\n", 
       "      <td>Lumos-Labs</td>\n", 
       "      <td>$3,100,000</td>\n", 
       "      <td>Jun  3, 2008</td>\n", 
       "      <td>Series_A</td>\n", 
       "    </tr>\n", 
       "  </tbody>\n", 
       "</table>\n", 
       "</div>"
      ]
     }, 
     "metadata": {}
    }
   ], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "source": [
    "This is the list of startup funding rounds and their respective dates. We now want to do a query from Twitter for the last 200 tweets before this date of the funding round. The code below does this using a Selenium web drive. We tried using the Twitter API, but it was unsuccesful because Twitter only allows you to scrape the last couple days."
   ], 
   "cell_type": "markdown", 
   "metadata": {}
  }, 
  {
   "execution_count": 69, 
   "cell_type": "code", 
   "source": [
    "comps = [name.replace('-', '') for name in list(funding_collapsed['Names'])]\n", 
    "series = list(funding_collapsed['Series_Type'])\n", 
    "dates = list(funding_collapsed['Series_Date'])\n", 
    "\n", 
    "\n", 
    "browser = webdriver.Firefox()\n", 
    "max_iters = len(comps)\n", 
    "start = time.time()\n", 
    "\n", 
    "# This was parallelized across multiple notebooks run by multiple people\n", 
    "for i in range(158, 1000):\n", 
    "    try: \n", 
    "        if i % 50 == 0:\n", 
    "            mins = (time.time() - start) / 60\n", 
    "            print 'Percent progress ' + str(100.0 * i / max_iters) + ' running for ' + str(mins) + ' mins'            \n", 
    "            backup(comp_tweets, i)\n", 
    "        \n", 
    "        # Get 200 tweets per company\n", 
    "        comp_name = comps[i]\n", 
    "        round_fund = series[i]\n", 
    "        date = dates[i]\n", 
    "\n", 
    "        start_end_dates = find_dates(date)\n", 
    "        if start_end_dates is None:\n", 
    "            errors.append((comp_name, round_fund, date))\n", 
    "            continue\n", 
    "        else:\n", 
    "            start_date, end_date = start_end_dates\n", 
    "\n", 
    "        if not comp_tweets.has_key(comp_name):\n", 
    "            comp_tweets[comp_name] = {}\n", 
    "        if comp_tweets[comp_name].has_key(round_fund):\n", 
    "            errors.append((comp_name, round_fund, date))\n", 
    "            continue\n", 
    "\n", 
    "        comp_tweets[comp_name][round_fund] = []\n", 
    "\n", 
    "        url = \"https://twitter.com/search?q=\" + comp_name + \"%20since%3A\" + start_date + \"%20until%3A\" + end_date + \"&src=typd&lang=en\"\n", 
    "\n", 
    "        browser.get(url)\n", 
    "        y_pos, y_pos_old = 0, -1\n", 
    "        for j in range(11):           \n", 
    "            if y_pos != y_pos_old:\n", 
    "                wait = WebDriverWait(browser, 30)\n", 
    "                time.sleep(1)\n", 
    "                browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n", 
    "                y_pos_old = y_pos\n", 
    "                y_pos = int(browser.execute_script(\"return window.scrollY;\"))\n", 
    "        \n", 
    "        html_source = browser.page_source\n", 
    "        soup = BeautifulSoup(html_source, \"lxml\")\n", 
    "\n", 
    "        for tweet in soup.find_all(\"li\"):\n", 
    "            if tweet.get('id') is not None:\n", 
    "                if tweet.get('id')[:17] == 'stream-item-tweet':\n", 
    "                    comp_tweets[comp_name][round_fund].append(str(tweet))\n", 
    "            \n", 
    "    except KeyboardInterrupt:\n", 
    "        try:\n", 
    "            sys.exit(0)\n", 
    "        except SystemExit:\n", 
    "            os._exit(0) \n", 
    "    except:\n", 
    "        errors.append((comp_name, series, date))"
   ], 
   "outputs": [
    {
     "output_type": "stream", 
     "name": "stdout", 
     "text": [
      "Percent progress 3.33667000334 running for 2.48515653213 mins\n", 
      "Percent progress 4.17083750417 running for 13.5679881175 mins\n", 
      "Percent progress 5.00500500501 running for 29.8278889497 mins\n", 
      "Percent progress 5.83917250584 running for 47.3346038342 mins\n", 
      "Percent progress 6.67334000667 running for 60.4890218178 mins\n", 
      "Percent progress 7.50750750751 running for 90.4858969013 mins\n", 
      "Percent progress 8.34167500834 running for 114.817298734 mins\n", 
      "Percent progress 9.17584250918 running for 144.381359633 mins\n", 
      "Percent progress 10.01001001 running for 158.611524598 mins\n", 
      "Percent progress 10.8441775108 running for 177.963723048 mins\n", 
      "Percent progress 11.6783450117 running for 201.168078498 mins\n", 
      "Percent progress 12.5125125125 running for 210.130816066 mins\n", 
      "Percent progress 13.3466800133 running for 231.395539149 mins\n", 
      "Percent progress 14.1808475142 running for 249.466241948 mins\n", 
      "Percent progress 15.015015015 running for 274.641155465 mins\n", 
      "Percent progress 15.8491825158 running for 296.378485099 mins\n"
     ]
    }
   ], 
   "metadata": {
    "collapsed": false
   }
  }, 
  {
   "execution_count": 70, 
   "cell_type": "code", 
   "source": [
    "# Final backup of the data\n", 
    "backup(comp_tweets, 1)"
   ], 
   "outputs": [], 
   "metadata": {
    "collapsed": true
   }
  }
 ], 
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2", 
   "name": "python2", 
   "language": "python"
  }, 
  "language_info": {
   "mimetype": "text/x-python", 
   "nbconvert_exporter": "python", 
   "name": "python", 
   "file_extension": ".py", 
   "version": "2.7.10", 
   "pygments_lexer": "ipython2", 
   "codemirror_mode": {
    "version": 2, 
    "name": "ipython"
   }
  }
 }
}